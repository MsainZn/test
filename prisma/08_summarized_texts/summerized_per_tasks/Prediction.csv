Title,DOI,Responsible,Method,Surgery/Modality,Summary,Evaluation,Limitations,Dataset (link),Size/Annotations,Ethnicities,Age range,Sex,Acquisition Centers
Reproducing Asymmetries Caused by Breast Cancer Treatment in Pre-Operative Breast Images,https://doi.org/10.1109/ISBI56570.2024.10635739,Helena,Traditional CV (Morphing) + GAN,Breast Cancer,Transfer asymmetries caused by breast cancer surgery from past post-operative patients into pre-operative images using 2 Methods: Affine transformations that reposition breast according to repositioned contour keypoints; Disentangled representation learning to separate identity from asymmetries in images and replace asymmetries of pre-operative patient with those of post-operative,Objective asymmetry metrics + SSIM between original and generated images,"Requires keypoint annotations. Restricted to modelling asymmetries, while ignoring other clinically-relevant features such as scars",Private (no link),"7600 images, 1021 images annotated with landmarks and aesthetic predictions",white (portuguese),N/R,F (breast cancer),Champalimaud Foundation
Predictive images of postoperative levator resection outcome using image processing software,https://doi.org/10.2147/opth.s116891,Helena,Photoshop,Blepharoptosis,Uses Photoshop to enlarge the eye,Patient-centric user study: 84.8% found the predictions useful,Requires additional effort from clinicians,Private (no link),109 eyes from 65 patients,N/R,"[39,90], mean=60",8M + 57F,Igo Ophthalmic Clinic
Usefulness of mirror image processing software for creating images of expected appearance after blepharoptosis surgery,https://doi.org/10.1007/s10792-020-01671-3,Helena,Mirroring Images,Blepharoptosis,Mirrors image where one of the eyelid of the patient was lifted with a curved hook,Patient-centric user study: 86.7% found the predictions useful,Assumes that face images are symmetrical,Private (no link),60 face sides from 30 patients,asian (japanese),"[42,84], mean=69",13M + 17M,Igo Ophthalmic Clinic
Data-based prediction of soft tissue changes after orthognathic surgery: clinical assessment of new simulation software,https://doi.org/10.1016/j.ijom.2014.08.006,Helena,Traditional CV (Morphing),Orthognathic Surgery,"Transfer displacement of feature keypoints from past post-operative patients into the current pre-operative image. Pipeline includes automatic facial feature detection, matching of facial features with those of an existing database, and morphing",Clinician-centric user study: compare similarity between real and predicted post-operative results; Objective metrics comparing keypoints of prediction and ground-truth,,Private (no link),database: 400 patients; inference: 15 patients,N/R,mean=27,146M+254F,N/R
Face Fusion: An Automatic Method For Virtual Plastic Surgery,https://doi.org/10.1109/ICIF.2006.301579,Helena,Traditional CV (Blending),Maxillofacial Surgery,"Transfers and blends image regions of post-operative image into pre-operative image. Authors propose pipeline with face boundary detection, eye/mouth bounding box detection, replacement of the bboxes of the query patient with the template and blending",No evaluation,Model was not applied to pre-/post-surgery images despite its motivation being for plastic surgery; the alterations alter the identity of the patient instead of the clinical surgery-related attributes of the images,Private (no link),N/R,N/R,N/R,N/R,N/R
Computer simulation tool for rhinoplasty planning,https://doi.org/10.1016/j.compbiomed.2003.10.006,Helena,Traditional CV,Rhynoplasty,Uses image warping to alter the nose of a pre-surgical image for simulating the results of a rhynoplasty. The clinician must annotate keypoints outlining the nose and manually alter them before applying warping to morph the image,No evaluation,Requires manual annotation of keypoints and their desired position,Private (no link),N/R,N/R,N/R,N/R,N/R
Morphing in rhinoplasty: predictive accuracy and reasons for use,https://pubmed.ncbi.nlm.nih.gov/21305919/,Helena,Photoshop,Rhynoplasty,Uses Photoshop to alter the structure of the nose,Subjective analysis comparing morphing result and post-op image,Requires additional effort from clinicians,Private (no link),133 patients,N/R,N/R,74F+59M,"Centre Hospitalier Regional de la Citadelle in Liege, Belgium"
Impact of Artificial Intelligence (AI) Image Enhancing Filters on Patient Expectations for Plastic Surgery Outcomes,https://doi.org/10.1007/s00266-024-04635-5,Helena,Filtering,,Clinical study concluding that methods for predicting post-operative results may raise expectations and lead to dissatisfaction after treatment (Potentially irrelevant paper),,The study only considers filtering techniques for image enhancement and does not apply any actual morphing algorithm suitable for the target surgery,,,,,,
Breast Decisions: Recommender System for Appearance Counseling about Breast Reconstruction,https://doi.org/10.1097/gox.0000000000004615,Helena,Retrieval,Breast,"Recommender system that recommends post-operative cases based on quantitative traists like breast volume and symmetry, as well as demographic traits like age and bra size.",Surgeon-centric study to verify the appropriateness of the recommendations,,Private (no link),505 women,N/R,N/R,F (breast cancer),University of Texas MD Anderson Cancer Center
,,,,,,,,,,,,,
Retrieval-Based Models,,,,,,,,,,,,,
Preoperative Computer Simulation in Rhinoplasty Using Previous Postoperative Images,https://doi.org/10.1089/fpsam.2019.0016,Pedro,Retrieval-based Morphing,Rhynoplasty,"Uses CBIR for predicting possible post operative results based on past patients. They use SVM to detect faces, then extract facial landmarks (68 points frontal, 19 points profile) and measure similarity with Euclidean distance. They swap the most similar postoperative nasal image regions onto the query image by partitioning it onto smaller regions (using Delauney triangulation method). Then, they post process texture and color automatically using OpenCV software's tools.",Accuracy,Only uses images and image-derived data. But skin thickness and inherent soft tissue healing potentials could be very relevant for the output. Also used a small dataset,Private (no link),400 images,N/R,N/R,360 F+ 40 M,Valiasr Hospital
Deep Aesthetic Assessment and Retrieval of Breast Cancer Treatment Outcomes,https://doi.org/10.1007/978-3-031-04881-4_9,Pedro,Retrieval,Breast Cancer,"Uses a simple deep neural network for the aesthetic evaluation of breast cancer treatment (to avoid overfitting, since the dataset is very small). Besides the deep neural network it also uses intermediate supervision for keypoint detection (such as nipple position and breast contours). These keypoints are used for assymetry measures.",Accuracy and balanced accuracy for classification performance (Excellent/Good vs Fair/Poor). Retrieval quality was evaluated by checking if the top-3 retrieved images belonged to the same or adjacent aesthetic classes.,"Very small dataset (only 143 images). Binary classification considers no difference between Excellent and Good , Fair and poor.",Available upon request,143 post-op images (TSIO + PORTO),white (portuguese),N/R,F (breast cancer),1 clinical center each
Digital Images in Academic Plastic Surgery: A Novel and Secure Methodology for Use in Clinical Practice and Research,https://doi.org/10.1177/1055665618787399,Pedro,Retrieval,Plastic Surgery,"Not on prediction, just a searchable database for securely storing and retrieving clinical images in plastic surgery (2D, 3D, 4D). The retrieval is based on metadata, not analyzing image content itself. It uses EPIC's Media Manager module within the eletronic health system to link multimedia files to patient records.",Response time,"Database does not store original 3D/4D images, only 2D snapshots which have a hyperlink or points to the external location of the 3D/4D images, which could be problematic in some cases ( if the location changes). Relies on metadata from health records, which may not capture all relevant clinical nuances",Private (no link),277000 images of 11000 patients,N/R,N/R,N/R,1 craniofacial clinic
Predicting Aesthetic Outcomes in Breast Cancer Surgery: A Multimodal Retrieval Approach,https://doi.org/10.1007/978-3-031-77789-9_14,Pedro,Retrieval,Breast Cancer,"Used 4 types of CBIR to predict aesthetic outcomes in breast cancer: Weighted Euclidean Distance and shallow ANN, CNNs, ViTs, multimodal fusion of image and tabular data. The best performance was obtained with fine-tuned multimodal ViTs",Contrastive Accuracy and Adjusted Discounted Cumulative Gain,"Relies heavily on clinician- annotated rankings, which can bring problems of subjectivity ",Private (no link),2193 instances with tabular data and images (CINDERELLA),white (portuguese),N/R,F (breast cancer),(dataset is being built with various clinical centres - not reported in paper)
,,,,,,,,,,,,,
Deep Generative Models,,,,,,,,,,,,,
A generative adversarial network approach to predicting postoperative appearance after orbital decompression surgery for thyroid eye disease,https://doi.org/10.1016/j.compbiomed.2020.103628,Joana, Generative (conditional GAN),Orthognathic Surgery (Orbital decompression for TAO),"cGAN Training: The generator  takes a label (pre-op or post-op) plus a random noise vector , while the discriminator  receives an image (real or generated) and the same label to decide if it’s real or fake.  Latent Vector Optimization: Once trained, the generator understands how pre-op faces differ from post-o. For a specific patient, start with a random z , fix  to “pre-op,” and iteratively adjust  so  matches the patient’s actual pre-op face. Switching to Post-op: Finally, you switch the label to “post-op” but keep z  the same. ","Quantitatively, the conditional GAN achieved higher SSIM scores than Pix2pix and CycleGAN, while MAE differences were minimal. Subjectively, 3 clinicians identified most images as post-op, but only about 27% were rated as realistic,","It was trained on a very small dataset (only 109 image pairs).  Requires a per-person latent vector optimization step to accurately capture individual facial features which is both time-consuming and computationally expensive. 
",https://data.mendeley.com/datasets/fdfvxx5vjg/1,109 pairs of pre/postop images,N/R,N/R,N/R,crawled images - from various centers
A Fully Automatic Postoperative Appearance Prediction System for Blepharoptosis Surgery with Image-based Deep Learning,https://doi.org/10.1016/j.xops.2022.100169,Joana,Generative (Pix2Pix conditional GAN),Ophthalmic Surgery (Blepharoptosis),"The architecture consists of four modules: an ocular detection module that identifies and segments the eye region, an analyzing module that measures eyelid dimensions using a reference sticker, a data processing module that crops and aligns images, and a prediction module. The prediction module leverages a Pix2Pix conditional GAN with an R2Unet backbone to generate postoperative images from preoperative inputs.","In the objective evaluations, the average overlap ratio between the predicted and real images was 0.858, the eyelid contour and predicted eyelid height analysis between the real and generated images revealed no significant differences.  In the subjective evaluations, 4 experts 
and 6 patients were satisfied (56.0% highly satisfied and 35.7% satisfied) and the average visual similarity was 9.43 (on a scale of 0 to 10). ",The system was developed and tested using images from a single surgeon,private,970 pairs of pre/post images from 362 patients,asian (chinese),"[0-77], avg=7.9",35.6% F,Second Affiliated Hospital of Zhejiang University
GOMPS: Global Attention-based Ophthalmic Image Measurement and Postoperative Appearance Prediction System,https://doi.org/10.1016/j.eswa.2023.120812,Joana,Generative (Pix2Pix conditional GAN),Ophthalmic Surgery (Blepharoptosis),"A system based on global attention to take measurements of ophthalmic parameters for diagnosing eye diseases and simultaneously predicting the post-operative appearance of blepharoptosis. The system uses Pix2Pix to predict the post-operative appearance, orientating the transformations with the medial corner and lower eyelid as anchor points. A naturalisation module incorporates the generated image back into the patient's face .","Quantitative methods such as Dice, IoU, specificity and average accuracy were used to analyse the segmentation performance of the models. Image generation used qualitative analysis, based on visual comparison of the generated images with the real post-operative images.",,OD2P(private) + CelebA,11635 pairs of pre/post images,N/R,N/R,N/R,N/R
An Automated Ptosis Screening and Postoperative Prediction System,https://doi.org/10.1109/ICICSP62589.2024.10809133,Joana,Generative(SC-FEGAN,Ophthalmic Surgery (Blepharoptosis),"The SC-FEGAN model is employed to generate postoperative prediction images by processing patients' facial images along with the expected upper eyelid elevation. Additionally, it offers manual refinement, allowing clinicians to adjust the shape and elevation of the upper eyelid as needed ​",no evaluation for the prediction,no quantitative measurements for the prediction,private,3314 images from 627 patients with landmark annotations,asian (chinese),N/R,N/R,Ninth People’s Hospital of Shanghai
PtosisDiffusion: a training-free workflow for precisely predicting post-operative appearance in blepharoptosis patients based on diffusion models,https://doi.org/10.3389/fcell.2024.1459336,Joana,Generative (Diffusion model),Ophthalmic Surgery (Blepharoptosis),"PtosisDiffusion is a training-free workflow that predicts postoperative appearance in ptosis patients using only preoperative images. It uses face mesh to compute ptosis-related measurements, particularly the Marginal Reflex Ratio (MRR). A target MRR, as defined by clinical expectation, is used to generate a Canny edge map and binary mask. These are input to a ControlNet-based diffusion inpainting pipeline, which guides Stable Diffusion to transform the eyelid region without compromising identity. The model requires no paired data or additional training and employs structural guidance and pretrained diffusion priors to simulate surgical outcomes. The model does not require paired data or additional training and relies on structural guidance and pretrained diffusion priors to simulate surgical outcomes.","Images of four models were graded by two ophthalmologists for overall quality, correction accuracy, and double eyelid creation. For statistical comparison, the normal eye in unilateral ptosis was used as a reference. Overlap ratio and MPLPD ratio were measured for the assessment of symmetry and eyelid alignment. PtosisDiffusion achieved the highest scores in all the criteria.","Postoperative images were not available, so evaluation relied on indirect symmetry metrics. The model also lacks fine-grained control since generated postoperative image MRR values can differ from the target (defined during generation) due to diffusion variability",Public (39 pre-op images in docx on paper) ,39 pre-operative images,N/R,N/R,N/R,N/R
Plasticgan: Holistic generative adversarial network on face plastic and aesthetic surgery,https://doi.org/10.1007/s11042-022-12865-5,Joana,Generative (GAN),"Plastic Surgery (teeth, face, ear, lips)","PlasticGAN is a conditional GAN framework producing post-surgery faces and simulating ageing. It uses a variational encoder for encoding an input face into a latent vector, which is combined with age and gender conditions and passed through a generator built upon BlockCNN-based residual blocks. A conditional discriminator, guided by WGAN-GP loss, and a VGG19-based perceptual loss ensure structural integrity and identity of the produced images. Multiple loss functions—including KL divergence, reconstruction, perceptual, adversarial, and total variation losses—are used during training, and the model does not require paired pre- and post-surgery images.","Qualitatively, the generated post-surgery images across different modalities (teeth, face, ear, and lips) were visually compared with outputs from other models, including tests on mask-wearing faces. Quantitatively, the model was assessed using age estimation and face verification metrics via the Face++ API, alongside image quality metrics like Inception Score and Fréchet Inception Distance.","The framework is trained on unpaired data, which may not capture the full range of surgical transformations across different modalities. Furthermore, the surgery-specific dataset is limited to only 24 paired pre- and post-surgery images collected via web-crawling, restricting the direct supervision available for accurately modeling surgical changes.","The dataset comprises 77,889 face images collected from public datasets including CACD, UTKFace, CLF, and Adience, with only 24 paired pre- and post-surgery images obtained via web crawling.",24 pairs of pre/postop pairs,N/R,N/R,N/R,crawled images - from various centers
3D-Guided Face Manipulation of 2D Images for the Prediction of Post-Operative Outcome After Cranio-Maxillofacial Surgery,https://doi.org/10.1109/tip.2021.3096081,Joana,Generative (GAN) 2d image manipulation based on 3d model,Cranio-maxillofacial surgery,"This paper proposes a semi-supervised GAN based on CycleGAN to predict 2D post-operative facial images from a pre-operative photo and a projected 3D shape (PNCC). Due to the lack of clinical image pairs, the model is trained on synthetic manipulations of the nose and chin—regions commonly affected by surgery. The generator takes the image and PNCC as input and outputs a modified face, while two discriminators evaluate global and local realism. Training combines image reconstruction loss, shape reconstruction loss via a shape estimator, and adversarial losses.","The model is evaluated qualitatively on synthetic nose and chin edits using visual samples, quantitatively using facial landmark errors (NME and CDF) on the AFLW2000 dataset, and on real clinical cases by comparing predicted and actual post-operative images using SSIM and face embedding distance. Clinicians also reviewed the outputs for assessment.","The model struggles more with nose edits than chin changes and sometimes softens extreme modifications. In some cases, it adds unrealistic features, like dark patches on chins in female faces, likely due to bias in the training data. Since it was only trained on nose and chin changes, it can’t handle other areas like the mouth or throat.","Public datasets: 300W-LP (trainning), AFLW2000(evaluation). Private: Four clinical cases from real patients",4 pairs of pre/post-op images and measurements,N/R,N/R,N/R,N/R
Turn Your Vision into Reality—AI-Powered Pre-operative Outcome Simulation in Rhinoplasty Surgery,https://doi.org/10.1007/s00266-024-04043-9,Joana,Generative (Pix2pix),Rhinoplasty surgery,"The study used a pix2pix Generative Adversarial Network (GAN) to generate postoperative rhinoplasty outcomes from pre-operative images. A dataset of 3,030 image pairs with images resized to 256×256 pixels and centered on the nasal dorsum. ","The model was evaluated by showing 101 participants sets of images containing a pre-operative photo and two post-operative images—one real and one GAN-generated. Participants were asked to identify the AI-generated image. The correct identification rate was 52.5%, indicating the generated images were hard to distinguish from real outcomes.","Evaluation was purely subjective, with no objective image quality metrics used. It relied only on 2D profile images. The model generated average outcomes rather than personalized predictions. ","The dataset consisted of 3,030 paired pre- and post-operative rhinoplasty images collected from the platform RealSelf",3030 pairs of pre/postop images,N/R,N/R,1015F,Collected from RealSelf
Plastic Surgery Image Classification and Generation,https://doi.org/10.1109/MIPR62202.2024.00057,Joana,Classification of type of surgery + Generative (multiples),"Cosmetic (Double Eyelid Surgery, Rhinoplasty, Face Contouring Surgery)","The paper presents a two-part method for analyzing plastic surgery effects using deep learning. For classification, models like ResNet and ResNeXt were used, with makeup normalization applied via BeautyGAN to reduce confounding factors. Surgery types were identified using facial landmark-based metrics, including eye ratios, nose proportions, contour smoothness, and symmetry. For generation, GANs such as CycleGAN, AttentionGAN, UNIT, and StyleGAN were used to synthesize post-surgery images, with StyleGAN producing the most realistic results. Generated images were then validated using the classification model to confirm surgical effect visibility.","The paper evaluates classification using accuracy, F1 score, and Cohen’s Kappa, achieving over 85% accuracy in detecting specific surgeries. Generation quality is assessed visually and by checking if the classifier can correctly identify surgery types in GAN-generated images","Image generation is only qualitatively evaluated (visual inspection and classifier agreement).The models are trained exclusively on Asian female faces, which limits generalizability to other ethnicities, genders, or facial structures.",private,1000 pre/post pairs,asian,"796 below 30 yo, 26 over 50 yo, 178 in between",F,public domain images (not reported centers)
Unsupervised generative model for simulating post-operative double eyelid image,https://doi.org/10.1007/s13246-024-01488-9,Joana,Generative (gan with attention),Double eyelid surgery,"The authors propose an unsupervised generative adversarial network (GAN) model to simulate post-operative double eyelid images from unpaired pre-operative 2D images. The model includes two generators and three discriminators, with an Attention-Class Activation Map (AcAM) module integrated into both components to guide attention to the eyelid region. A modified Adversarial Consistency Loss (ACL) is used to remove occlusions and preserve structural features. The model also incorporates Identity Loss to maintain content consistency and Least Squares GAN Loss to stabilize training. The approach does not require paired data and operates on 2D image inputs.","The method was evaluated using FID and KID metrics, achieving the lowest scores among compared models. An ablation study showed that removing AcAM, identity, or ACL loss increased error metrics. A user study with three volunteers also ranked the method highest in perceived realism across 146 test cases.",,private,1460 unpaired pre/post images,asian (chinese),N/R,N/R,Shanghai Jiao Tong University School of Medicine
BreastGAN: Artificial Intelligence-Enabled Breast Augmentation Simulation,https://doi.org/10.1093/asjof/ojab052,Joana,Generative (pix2pix),Breast Augmentation,The method uses a conditional GAN (Pix2Pix) that receives a frontal preoperative image as input and generates a simulated postoperative image as output. It was trained on paired real clinical before-and-after images of breast augmentation.,"Assessment was primarily visual, highlighting similarities and the model’s progression across training epochs. Quantitative metrics were acknowledged but not emphasized.","The GAN was trained on images from a single surgeon, limiting generalizability to other surgical styles.. Augmentation parameters such as implant size were not included, so the model cannot generate controlled or personalized results. Additionally, the model sometimes introduced skin color shifts between pre- and postoperative images and altered non-target areas of the body, reducing visual accuracy.",private,1235 pre/post pairs,N/R,N/R,F (breast augmentation),N/R
CleftLipGAN : Interactive GAN-Inpainting for Post-Operative Cleft Lip Reconstruction,https://openaccess.thecvf.com/content/ACCV2024W/GAISynMeD/html/Atputharuban_CleftLipGAN__Interactive_GAN-Inpainting_for_Post-Operative_Cleft_Lip_Reconstruction_ACCVW_2024_paper.html,Joana,Generative (inpaiting GAN),Cleft Lip,"GAN-based inpainting model that reconstructs post-operative Cleft lip images using healthy face data. The model uses fixed masks and edge contours (derived from facial keypoints) to guide the inpainting process, focusing on the upper lip and philtrum region. It features a gated convolutional generator with attention modules and a patch-wise discriminator enhanced with CLIP-based semantic features. A key component is its interactive interface, allowing users to adjust lip landmarks in real time to generate diverse and anatomically realistic Cleft outcomes.","CleftLipGAN was evaluated using PSNR, SSIM, and BRISQUE, outperforming other inpainting models. Qualitative results on real Cleft images showed more realistic, detailed reconstructions, with support for interactive editing to generate diverse outcomes.","The study is limited by the lack of clinical validation and reliance on healthy facial data, which may not capture the full variability of Cleft anatomy. The model does not directly learn or understand Cleft deformities—it reconstructs lips based on user-guided keypoints, simulating outcomes rather than modeling true pathology. Additionally, the test set of real Cleft cases is small",private,164 postop images,white (Ireland),children,N/R,Children’s Health Ireland
A Feasibility Study on Image Inpainting for Noncleft Lip Generation from Patients with Cleft Lip,https://doi.org/10.1109/BHI56158.2022.9926917,Joana,Generative (GAN),Cleft Lip,"The paper proposes a multi-task deep learning model for facial image inpainting that generates non-cleft lip and nose regions from masked images of patients with cleft lip. The model jointly performs image inpainting and facial landmark prediction, using shared features and adaptive fusion blocks to enable information exchange between tasks. Landmark predictions are converted into binary maps and integrated into the inpainting process to guide structure reconstruction. The method is trained on CelebA and tested on real patient datasets without using cleft lip images during training to protect privacy.","The method is evaluated on CelebA using PSNR, SSIM, and FID, showing improved image quality over existing methods. On clinical datasets CleftLip10 and CleftLip24, expert surgeons ranked the results, with the proposed model achieving the highest validity and best average ranking. An ablation study confirmed the benefit of multi-task learning and landmark integration.",the inpainting masks are manually defined,"private, public (CelebA)",10 pre/post pairs + 24 pre images,white (England),children,N/R,"Royal Victoria Infirmary
(RVI) in Newcastle upon Tyne"
An artificial intelligence tool for image simulation in rhinoplasty,https://doi.org/10.1055/s-0041-1729911,Joana,Generative (GAN),Rhinoplasty,"The paper’s method trains a Generative Adversarial Network (GAN) on paired preoperative and surgeon-simulated rhinoplasty images to generate new simulated outcomes from patient profile photos, replicating the surgeon’s style.","For evaluation, specialists were shown randomized pairs of AI-generated and surgeon-generated simulation images and rated their agreement with each using a seven-point Likert scale, allowing comparison of the AI’s output to the surgeon’s standard.",trained only on images from a single surgeon,,1200 pairs of pre images and simulated outcomes,N/R,N/R,N/R,N/R
,,,,,,,,,,,,,
3D-Based AI Models,,,,,,,,,,,,,
DeltaFace: fully automatic 3D facial cosmetic surgery simulation,https://doi.org/10.1109/ICSEC53205.2021.9684623,Gonçalo,Retrieval + CNN for 3d Reconstruction + Convolution Autoencoder for selecting the most similar faces,Cosmetic Surgery - Various (Face),"The study presents an automated method to simulate cosmetic surgery results by leveraging a pre and post-operative face pairs dataset. The system identifies a similar pre-operative face to a given input and transfers the surgical changes observed in its corresponding post-operative image. This transfer is guided by both 3D mesh information and 2D image data, and a convolutional autoencoder is employed to predict the final post-surgery appearance.",Generic user study by surveying 24 people regarding the predictions of the model. No objective metrics.,,Private (no link),477 pre-post image pairs + 3D mesh (obtained based on the pre-post pairs),N/R,N/R,N/R,N/R
Development of novel artificial intelligence systems to predict facial morphology after orthognathic surgery and orthodontic treatment in Japanese patients,https://doi.org/10.1038/s41598-021-95002-w,Gonçalo,geometric morphometric methods (GMMs) + deep learning,orthognathic surgery + orthodontic treatment,"This paper describes the development of two novel artificial intelligence (AI) systems designed to predict three-dimensional (3-D) facial morphology following either orthognathic surgery (System S) or orthodontic treatment (System E). The researchers used a combination of landmark-based geometric morphometric methods (GMM) and deep learning techniques, employing pre-treatment cephalometric data and 3-D facial images as predictive variables. The accuracy of these AI systems was then evaluated using data from Japanese patients who had undergone these treatments. The results showed that AI systems to predict facial morphology after treatment were clinically acceptable.",,,Private (no link),137 pre/post 3D facial images annotated with landmarks,asian (japanese),"[15,37]",N/R,Osaka University Dental Hospital
Cranio-maxillofacial post-operative face prediction by deep spatial multiband VGG-NET CNN,https://pubmed.ncbi.nlm.nih.gov/35559377/,Gonçalo,Deep CNN,maxillofacial treatments,"The paper addresses the limitations of traditional surgical planning in cranio-maxillofacial surgery by presenting a deep-learning solution for predicting post-operative facial appearance. The authors developed a deep spatial Multiband VGG-NET Convolutional Neural Network (CNN) that utilizes pre-processed patient CT scan data, operating a multiband approach to analyze information across different spatial frequencies.",,,Private (no link),313138 head CT scans,N/R,N/R,N/R,multi-center
Deep learning for biomechanical modeling of facial tissue deformation in orthognathic surgical planning,https://doi.org/10.1007/s11548-022-02596-1,Gonçalo,"Deep Learning to predict  soft-tissue
deformation",orthognathic surgery,"This paper presents a biomechanics-informed deep learning model based on PointNet++ to predict soft-tissue deformation for orthognathic surgery planning. The model approximates finite element method (FEM) simulations while significantly reducing computation time. It accepts point cloud data, input displacements, and explicit boundary-type information. Testing on FEM-generated datasets showed mixed results regarding the impact of explicit boundary types, with improved performance in large deformations but reduced accuracy in small ones.",,,Private (no link),5 subjects; CT scans,N/R,N/R,N/R,1 center
Deep Learning-Based Facial Appearance Simulation Driven by Surgically Planned Craniomaxillofacial Bony Movement,https://doi.org/10.1007/978-3-031-16449-1_54,Gonçalo,Attentive Correspondence assisted Movement Transformation network - similar to deep learning but don't overlook the physical relationship between bone and soft tissue,orthognathic surgery,"This work introduces ACMT-Net, a deep learning-based model designed for simulating facial appearance changes after bony movement in orthognathic surgery. Unlike conventional deep learning methods that ignore the physical correspondence between bone and soft tissue, ACMT-Net incorporates an attentive correspondence matrix to establish a direct mapping between them. Experimental results show that ACMT-Net achieves prediction accuracy comparable to the SOTA finite-element method (FEM) while significantly reducing computational complexity.",,,Private (no link),40 patients with paired pre/postop head CT scans and landmarks,N/R,N/R,N/R,1 center
Correspondence attention for facial appearance simulation,https://doi.org/10.1016/j.media.2024.103094,Gonçalo,ACMT-Net with a k-Nearest Neighbors based clustering,orthognathic surgery,"Similar to the previous paper, the results again showed accuracy identical to that of SOTA methods while increasing performance.",,,Private (no link - same as 1 before this) ,40 patients with paired pre/postop head CT scans and landmarks,N/R,N/R,N/R,1 center
Simulation of Postoperative Facial Appearances via Geometric Deep Learning for Efficient Orthognathic Surgical Planning,https://doi.org/10.1109/TMI.2022.3180078,Gonçalo,facial shape change prediction network (FSC-Net),orthognathic surgery,"FSC-Net is a deep learning-based framework to accelerate postoperative facial appearance prediction in orthognathic surgery. Unlike traditional biomechanical models, which are computationally expensive, FSC-Net learns a nonlinear mapping from bony shape changes to facial shape changes using weak supervision from paired pre- and postoperative data. It incorporates a distance-guided shape loss to emphasize the jaw region and a local point constraint loss to maintain surface smoothness. Experimental results show that FSC-Net achieves a 15× speedup while maintaining accuracy comparable to state-of-the-art finite-element modeling (FEM) methods.",,,Private (no link - same as 2 before this),40 patients with paired pre/postop head CT scans and landmarks,N/R,"[18,35]",24F+16M,1 center
Deep Simulation of Facial Appearance Changes Following Craniomaxillofacial Bony Movements in Orthognathic Surgical Planning,https://doi.org/10.1007/978-3-030-87202-1_44,Gonçalo,"FC-Net, a facial appearance change simulation network",orthognathic surgery,"This work introduces FC-Net, a deep-learning framework to predict postoperative facial appearance changes in orthognathic surgery. Unlike conventional biomechanical methods such as finite element modeling (FEM), which are computationally expensive, FC-Net learns point displacement vectors from a preoperative facial point cloud using weak supervision from paired bony movement data. To maintain facial topology, the model employs a local-point-transform loss to constrain local point movements. Experimental results demonstrate that FC-Net achieves prediction accuracy comparable to FEM while significantly reducing computational time, making it more suitable for clinical use.",,,Private (no link - same as 3 before this),40 patients with paired pre/postop head CT scans and landmarks,N/R,N/R,N/R,1 center
Statistical model based 3D shape prediction of postoperative trunks for non-invasive scoliosis surgery planning,https://doi.org/10.1016/j.compbiomed.2014.02.015,Gonçalo,least squares support vector regression (LS-SVR),scoliosis surgery,"This study presents a least squares support vector regression (LS-SVR) approach to predict scoliosis patients' postoperative 3D trunk shape after spinal surgery. Since aesthetic outcomes constitute a significant patient concern, this method aids surgical planning by providing a preoperative visualization of results. Results show that the simultaneous decomposition of predictors and response variables yields the most accurate 3D shape predictions, offering a valuable tool for aligning surgical outcomes with patient expectations.",,,Private (no link),141 samples -> 3D surface geometry ,N/R,"[11,18]",N/R,Sainte-Justine Hospital Research Center
Maxillofacial bone movements-aware dual graph convolution approach for postoperative facial appearance prediction,https://doi.org/10.1016/j.media.2024.103350,Gonçalo,dual graph convolution based,orthognathic surgery,"This work presents a deep-learning model for predicting postoperative facial appearance, addressing limitations in existing methods that neglect facial surface geometry and topology. Unlike conventional approaches that process facial point clouds independently, the proposed dual graph convolution model captures detailed facial structures by learning from graphs constructed in Euclidean and geodesic spaces. It also employs a coarse-to-fine prediction strategy to improve robustness and accuracy. Evaluations of clinical data show that the method achieves superior performance compared to current deep learning techniques.",,,Private (no link),40 patients - CT head scans with landmarks,N/R,N/R,N/R,Shanghai Ninth People’s Hospital
A new system for computer-aided intraoperative simulation and postoperative facial appearance prediction of orthognathic surgery,https://doi.org/10.1109/MMSP.2008.4665063,Gonçalo,Reconstruction system,orthognathic surgery,"This paper introduces a computer-aided system for orthognathic surgery that reduces reliance on costly and high-radiation imaging like CT or MRI. The system reconstructs a 3D skull model using orthogonal radiographs, facial mesh data from a 3D laser scanner, and a built-in skull template. It enables virtual surgical simulations through interactive bone cutting. A specialized registration process aligns the skull with the facial skin model, allowing for postoperative appearance prediction. The system was successfully applied in a clinical case, yielding satisfactory results.",2008,,,,,,,
Artificial Intelligence for Rhinoplasty Design in Asian Patients,https://doi.org/10.1007/s00266-023-03534-5,Gonçalo,modified FoldingNet model,Rhinoplasty,"This study introduces an AI-based method for automated preoperative 3D simulation in rhinoplasty to improve efficiency and consistency in nasal contour design. By training a modified FoldingNet model on 3D facial point cloud data from 209 patients, the system learns to replicate manually designed outcomes, reducing reliance on individual aesthetics and surgical experience. The model captures over a thousand facial features and mimics human aesthetic judgment and task-specific optimization. Results show that the AI-generated designs closely align with manual ones, offering a promising new paradigm for personalized and efficient surgical planning in plastic surgery.",,,Private (no link),209 patients - 3 digital photos used to build 3d image,N/R,"[18,65]",164F + 45M,1 center
A machine learning framework for automated diagnosis and computer-assisted planning in plastic and reconstructive surgery,https://doi.org/10.1038/s41598-019-49506-1,Gonçalo,3D facial morphable model,facial plastic and reconstructive surgery,"This work presents a large-scale machine-learning framework for facial plastic and reconstructive surgery, introducing the first clinical 3D morphable model trained on 4,261 facial scans. Designed to overcome the limitations of current planning tools, the model enables automated diagnosis, risk assessment, and surgical outcome simulation with high accuracy and minimal manual input. Achieving 95.5% sensitivity and 95.2% specificity, it supports patient-specific treatment planning directly from 3D scans, enhancing clinical decision-making and doctor-patient communication.",,,Private (no link),274 3D surface scans from 151 patients,"ethnicity = 76% White, 10% Asian, 10% Mixed Heritage/Other, and 8% Black",mean age = 18.4 ± 2.4 years,44% male and 56% female,2 centers: Boston Children’s Hospital and Yale-New Haven Hospital
Real time 3D simulation for nose surgery and automatic individual prosthesis design,https://doi.org/10.1016/j.cmpb.2010.09.001,Gonçalo,Laplacian surface deformation,nose surgery,"This paper presents a nose surgery planning and simulation system that combines 3D laser scans with lateral X-ray images to predict postoperative appearance and automatically design patient-specific prostheses. The system reconstructs the internal nose structure by integrating statistical soft tissue thickness data with individual X-ray measurements. Real-time simulation is driven by Laplacian surface deformation, allowing manual or automatic contour adjustments based on aesthetic standards. Once the desired appearance is achieved, the system generates a custom prosthesis model. Surgeons found the tool intuitive and promising for clinical use.",,,Private (no link),6 pre/post-op pairs of 3D skin surface,N/R,N/R,N/R,1 center
,,,,,,,,,,,,,
Computer Graphics Works (Mostly Finite Element Models),,,,,,,,,,,,,
Simulation of the postoperative trunk appearance in scoliosis surgery,https://doi.org/10.1109/ISBI.2012.6235778,Mohammad,3D soft tissue deformation FEM,Scoliosis surgery,"The method utilizes 3D optical digitizers for external trunk surface acquisition and biplanar radiographs (postero-anterior and lateral views) for 3D reconstruction of bone structures like the spine and rib cage. The paper describes a method for simulating the postoperative trunk appearance in scoliosis surgery, which aims to help clinicians illustrate potential surgical results to patients and aid in surgical strategy decisions. The approach models the physical behavior of soft tissues after spinal intervention and has shown promising qualitative and adequate quantitative accuracy for clinical assessment, with a short simulation time suitable for interactive clinical environments","The method was evaluated qualitatively through 3D visualization of simulated and actual postoperative external trunk surfaces, and quantitatively by comparing differences in maximal back surface rotation (BSR) of cross-sections between vertebral levels T3 and L5. A mean absolute difference of 1.15 degree (thoracic) and 1.90 (lumbar) on the BSR index was obtained, falling within the range of the smallest statistically significant difference","Current limitations include incomplete personalization of anatomical structures, as the spine model is generated by deforming generic vertebrae models based on a limited number of manually identified landmarks from radiographs, which can be error-prone. Additionally, the tetrahedral mesh generation does not account for the different layers of soft tissue (skin, fat, muscles), and the model does not consider the exact physical properties of the trunk soft tissue, which may vary with scoliosis type",Private (no link),surface geometry + LAT and PA radiographs - 1 patient,N/R,N/R,N/R,1 center
Differentiable Simulation for Outcome-Driven Orthognathic Surgery Planning,https://doi.org/10.1111/cgf.14623,Mohammad,FEM with Sparse Gauss-Newton solver,Orthognathic and Maxillofacial surgery,"The anatomical model for the simulation is created from cone-beam CT (CBCT) and 3D facial surface scans. The facial scan is also used to generate high-quality visualizations of the deformed simulation mesh. This paper introduces a differentiable FEM simulator to improve virtual surgery planning for orthognathic surgery by addressing the challenging inverse problem of estimating optimal treatment parameters. It proposes defining a parametric treatment model, optimized using analytically derived simulation gradients against an objective on the facial 3D surface. This approach allows for interactive exploration of the solution space with first-order approximations, helping surgeons visualize the impact of parameter variations. The method robustly converges to a feasible post-treatment shape, even with a sparse set of guiding landmarks, and aims to simplify the integration of simulation-based VSP tools into clinical workflows.","The method was tested on simulation meshes presenting Angle's classes II and III, including cases with strong asymmetry, designed under the supervision of maxillofacial surgeons. The evaluation showed that the parameters of the surgical model can be effectively optimized, reducing the average distance to target landmarks from 6.3 mm to 1.6 mm. The optimization typically converged in one or two steps, with an average computation time of about 20 minutes on a consumer laptop. First-order predictions of the model were found to be reasonable, with a maximum error of 3mm for a 20mm facial displacement, allowing for rapid, interactive exploration of potential outcomes.","The authors note that validation against data from a diverse patient population is necessary before the method can be used clinically. There is a challenge in finding an ""appropriately stiff"" model that converges to only feasible treatments, as relaxing physical constraints can lead to unrealistic deformations. The current blendshape model, while incorporating surgical prior knowledge, may not represent all surgically feasible transformations, and extending it to new patients is non-trivial. Further investigation is needed into optimal treatment models and incorporating variables related to tissue cutting, removal, and damage, as well as automating treatment planning by suggesting post-treatment targets.",Private (no link),conebeam CT (CBCT) and a 3D facial surface scan,N/R,N/R,N/R,N/R
Soft tissue prediction in orthognathic surgery: Improving accuracy by means of anatomical details,https://doi.org/10.1371/journal.pone.0294640,Mohammad,Soft tissue prediction using FEM and sensitvity analysis using DoE,Bimaxillary Orthognathic Surgery,"The imaging modalities used in this study include Cone Beam Computed Tomography (CBCT) and Magnetic Resonance Imaging (MRI). CBCT scans were used to acquire hard tissue data (skull and mandible), while MRI scans provided detailed information for segmenting facial muscles and skin. Planar x-rays were also part of the standard presurgical evaluation.  The authors improved the Rubin-Bodner (RB) model to predict facial soft tissue deformation after CMF surgery. They used a Generalized Regression Neural Network (GRNN) to train elastic parameters based on different CMF surgical types. Finite Element Method (FEM) was applied to calculate stress at each node in the RB model. Finally, Kernel Ridge Regression (KRR) was implemented to establish the relationship between bone displacement and stress, allowing for the prediction of soft tissue deformation from facial bone displacement.","The model was evaluated by comparing the predicted soft tissue changes from the homogeneous model with postoperative 3D CBCT scans of patients. The quantitative distance error between the homogeneous model and actual patient surfaces for the midface area was 0.55 mm with a standard deviation of 2.29 mm. A Design of Experiments (DoE) approach, along with local sensitivity analysis and the Wilcoxon signed-rank test, was used to assess the effect of muscle presence and stiffness variation on landmark displacement, identifying statistically significant impacts of certain muscles","The study acknowledged several limitations, including a small cohort size of eight patients, attributed to the extensive image processing and computational analysis required, although 25 simulations per patient were performed. Another limitation was the use of different head positions during MRI (supine) and CBCT (neutral) scans, which might slightly affect the relative positions of soft and hard tissues. The study also noted unrecorded postoperative weight loss, which could influence soft tissue thickness changes, and the neglect of BSSO movement as the focus was on the upper jaw. Furthermore, the necessity for a preoperative MRI limits clinical applicability to patients not needing fixed orthodontic appliances, and the time-consuming nature of muscular structure segmentation and FEM computation makes the current protocol impractical for routine preoperative planning. The biomechanical properties of nasal cartilaginous structures were also not specifically addressed",Private (no link),8 patients: postop conebeam CT (CBCT) and MRI,N/R,"[18,66], mean=34",5F + 3M,St Orsola–Malpighi University Hospital
Prediction of facial soft tissue deformations with improved rubin-bodner model after craniomaxillofacial (CMF) surgery,https://doi.org/10.1109/ICIP.2015.7351312,Mohammad,"Rubin-Bodner model with GRNN for elastic parameters, FEM for stress calculation, and KRR to relate bone displacement and soft tissue deformation for CMF surgery prediction",Craniomaxillofacial (CMF) surgery,The study utilizes pre-operative and post-operative CT data and 3D facial surface scans from a 3D surface camera. An anatomic detailed mesh template is also used. This paper presents an integrated system for predicting facial soft tissue deformation after CMF surgery. The system improves upon the Rubin-Bodner (RB) model by incorporating a Generalized Regression Neural Network (GRNN) to train elastic parameters specific to different CMF surgical types. It then uses Finite Element Method (FEM) to calculate stress and Kernel Ridge Regression (KRR) to model the relationship between bone displacement and soft tissue deformation. The approach aims to overcome limitations of individual-based methods by incorporating population-based statistical information and patient-specific biomechanical data.,"The system's accuracy was assessed using leave-one-out cross-validation with 11 patients. The performance was evaluated by calculating the difference between predicted and actual post-operative soft tissue deformation, measured as the root mean squared error (RMSE) for GRNN and average displacement difference for KRR. The improved RB Model (RBM) demonstrated more accurate prediction accuracy compared to other methods like Statistical Deformation Model (SDM), Linear Finite Element Method (LFEM), and Incremental Kernel Ridge Regression (IKRR). Visual inspection also showed RBM's predictions to be more faithful to postoperative images and to delineate more natural facial contours","The paper mentions that the accuracy of the Statistical Deformation Model (SDM) heavily relies on the quantity of sample data, and insufficient sample size can lead to low accuracy. Additionally, while LFEM and IKRR provide comparatively accurate predictions, they fail to consider the property of different facial tissues affected by different CMF surgical plans. The study also notes that the short-term soft tissue deformation is ignored by only utilizing hyperelastic terms and disregarding time-dependent factors related to transient and dissipative material behaviors.",Private (no link),11 patients: pre/post-op pairs of CT data and 3D facial surface scans,N/R,N/R,N/R,N/R
Patient specific finite element model of the face soft tissues for computer-assisted maxillofacial surgery,https://doi.org/10.1016/S1361-8415(02)00108-1,Mohammad,Generic FEM model for face soft tissues,Maxillofacial orthognathic surgery,"This research focuses on predicting face soft tissue deformations resulting from bone repositioning in maxillofacial surgery. It introduces a generic 3D Finite Element model of facial soft tissues, which incorporates muscles and their mechanical properties. This model is automatically adapted to individual patient anatomies using elastic registration of CT-segmented skin and skull surfaces. The aim is to provide a robust and clinically compatible tool for pre-operative planning, enabling surgeons to visualize and predict post-operative aesthetic and functional outcomes of bone displacements","The evaluation involved both qualitative and quantitative assessments. Qualitative validation of the models' adequation to patient morphologies and the coherence of simulated post-operative aspects was performed by five specialized surgeons. Quantitative evaluation focused on the accuracy of the mesh conformation, with root mean square errors between 0.3 and 0.55 mm for every model. The robustness of the registration process was also evaluated on six diverse patient morphologies","The model assumes a linear elastic behavior for facial tissues, which is not accurate for strains over 15%. Additionally, the model currently lacks collision detection and contact modeling between lips and teeth, which can lead to unrealistic lip movements during simulations of muscle contraction. The automatically generated meshes from existing methods were found to lack robustness and required several hours of computation, leading to the development of a semi-automatic approach. Initial qualitative evaluation by surgeons also noted the lack of eyes and neck in the model and perceived flatness in frontal views, along with underestimated nostril and cheekbone contours for certain patient profiles",Private (no link),6 patients: preop CT scans,N/R,N/R,N/R,Plastic and Maxillofacial Department
A novel incremental simulation of facial changes following orthognathic surgery using FEM with realistic lip sliding effect,https://doi.org/10.1016/j.media.2021.102095,Mohammad,Incremental soft tissue prediction using FEM,Orthognathic and osteotomy of jaw bone Surgery,"This research proposes and validates an innovative incremental simulation method using FEM to accurately predict facial soft-tissue changes, particularly in the lip area, following orthognathic surgery. The method integrates a patient-specific, lip-detailed FE mesh and incorporates a realistic lip sliding effect, in addition to the mucosa sliding effect. This comprehensive approach demonstrably improved prediction accuracy in the lip region when compared to conventional FEM techniques. The goal of this advanced prediction method is to revolutionize current surgical planning for orthognathic procedures by enabling adjustments to bone surgical plans based on anticipated facial changes, ultimately leading to optimal surgical outcomes.","The proposed method was quantitatively assessed using 35 retrospective clinical datasets. The evaluation compared the surface deviation error of the new method against both traditional FEM simulation and FEM with only mucosa sliding effect, demonstrating significant improvement in the upper and lower lips. Additionally, a lip-shape analysis, which mirrors clinicians' qualitative evaluations, confirmed substantial improvements in lip prediction accuracy for the lower lip and the entire lip region.","The provided paper does not explicitly detail the limitations of the specific novel method presented. However, it does discuss general challenges and limitations within the broader field, such as the existing FEM prediction accuracy around critical regions like the lips being clinically unacceptable and previous methods failing to simulate independent upper and lower lip movements. Additionally, the paper mentions difficulties in manual digitization of lip surfaces due to poor CT image quality, artifacts from orthodontic appliances, and the empirical assumption that the effect of orthodontic braces on the simulation is negligible",Private (no link),35 patients: pre- and postoperative CT and 3D photographs,N/R,23.0 ± 4.0 years old,17 females and 18 males,1 center
Simulation of Lipofilling Reconstructive Surgery Using Coupled Eulerian Fluid and Deformable Solid Models,https://doi.org/10.1007/978-3-642-40760-4_38,Mohammad,2.5D Eulerian Fluid-Solid Interaction (FSI) model,Reconstructive fat-filling facial surgery,"The paper presents a method for simulating reconstructive facial surgery involving fat-filling, which couples a 2.5D Eulerian fluid model for the fat with a finite element model for the soft tissues. The coupling of the two models is achieved through the computation of the mechanical compliance matrix. The fluid solver incorporates properties of solid tissues and fluid pressure , where the pressure deforms the solids. The fluid model is based on an Eulerian fluid model with a velocity and pressure field, extended to a 2.5D formulation by adding a fluid height field. The simulation process involves computing external forces, diffusion for viscosity, advection for turbulence, and projection for fluid incompressibility. The deformable solid model uses finite element methods, with computational cost reduced by using corotational strain measure. The fluid-solid interaction is handled by combining fluid pressure and mechanical constraints equations, leading to a coupled system that considers height variations from solid motion.","The model was tested on a simple square domain with a rigid and a deformable solid, demonstrating convergence with different time-steps and mesh resolutions, and coherence across varying stiffness values. For facial fat-filling, the simulation used patient-specific data, starting with a 3D mesh of the face and creating three tissue layers. The simulated fat injection deformed tissues based on fluid pressure and tissue stiffness, generating a change in cheek shape. The results were compared to the actual post-surgery shape of the patient, showing similar deformations and realistic behavior, despite some differences. The computation time for each step averaged 0.6 seconds with a 10 ms time-step, with the most expensive operation being the computation of the compliance matrix","The current model has several limitations. The computational speed could be improved, particularly by optimizing the inversion of the mechanical stiffness matrix or using approximation methods. The fluid model does not currently include visco-elastic properties, despite fat being a material between a fluid and a solid. The tissue model uses constraints to simulate obstacles, but these do not incorporate actual ligament properties and should be more elastic. Additionally, the tissue layers in the current model have a uniform thickness, and a more accurate description of tissue thickness could provide more realistic behaviors",Private (no link),3D mesh based on laser scan,N/R,N/R,N/R,N/R
Orbital and maxillofacial computer aided surgery: patient-specific finite element models to predict surgical outcomes,https://doi.org/10.1080/10255840500289921,Mohammad,Patient-specific Iterative regularized FEM solver,Maxillofacial orthognathic surgery,"The paper proposes a methodology for automatically building patient-specific finite element (FE) models of anatomical structures using a mesh-matching method, followed by a process that corrects mesh irregularities. The mesh-matching algorithm generates patient-specific volume meshes from an existing generic model. The mesh regularization process is based on the Jacobian matrix transform, which is checked at each node, and if negative or nil, the element is classified as irregular and iteratively shifted until regular.","For maxillofacial surgery, the prediction of the FE model for one patient was qualitatively compared with the patient's post-operative appearance measured from a CT scan. For orbital surgery, the methodology was evaluated by generating 11 patient-specific FE poroelastic models, and an average law linking osteotomy size and eyeball backward displacement was extrapolated from simulations for each patient model. The regularization algorithm's computational time, number of iterations, and node displacements were also reported for both applications.","One recognized limitation of the regularization method is its inability to guarantee that the algorithm will correct any irregular mesh, as its iterative process tries to find a global solution without theoretical convergence guarantees. Additionally, in the orbital surgery application, the rheological variability among patients (e.g., Young modulus, Poisson's ratio, porosity, and permeability) was unknown and therefore defined identically for all models, which could be a limitation.",Private (no link),11 patients,N/R,N/R,N/R,"Maxillofacial Department, Toulouse Hospital, France"
A Regression Model for Predicting Shape Deformation after Breast Conserving Surgery,https://doi.org/10.3390/s18010167,Mohammad,Random Forest & Gradient Boosting Regressor,Breast Conserving Surgery,"The study proposes a methodology for predicting breast deformation after Breast Conserving Surgery (BCS) using machine learning techniques, specifically Random Forests (RF) and Gradient Boosting Regression (GBR). The process involves creating an in-house semi-synthetic dataset using Magnetic Resonance Imaging (MRI) data from real patients and an existing breast cancer surgery simulator. The methodology focuses on feature engineering, machine learning approaches, and numerical evaluations to predict breast shape. The models learn breast deformations from exemplar data, aiming to overcome the computational time demands and expertise requirements associated with traditional biomechanical simulations","The evaluation of the proposed regression models, specifically Random Forests (RF) and Gradient Boosting Regression (GBR), involved numerical assessments using pair-wise and global distances between predicted point clouds (PCLs) and post-surgery models. The mean distance (µ), standard deviation (σ), and maximum distance (Max) were reported for these metrics. Visual comparisons of predicted breasts were also performed, categorized as poor, fair, and good predictions based on average pair-wise distances. The study concluded that the RF regressor with an adaptively weighted training set generally outperformed Multi-Output Regression (MOR) and GBR in terms of both average and Hausdorff objective functions, indicating better prediction performance.","A primary limitation noted in the paper is the non-existence of an appropriate dataset containing breast data before and after surgery to directly train a learning model for breast healing deformations. To overcome this, an in-house semi-synthetic dataset was constructed. Additionally, the existing biomechanical models, while capable of predicting deformations, suffer from limitations such as high computational costs (taking hours or even days) and high-end hardware requirements, making them impractical for daily clinical use. Fidelity concerns also exist due to simple representations and unverified parameters in many biomechanical models. The characterization of individual-specific parameters for personalized models remains an unsolved challenge. For multi-output regression (MOR), the paper mentions poor results compared to Random Forests, indicating a limitation in its performance within this context.",Private (no link),6 patients: preop MRI,N/R,N/R,N/R,Royal Free Hospital in London
A Computer-based Surgery Planning and Simulation for the Prediction of 3D Postoperative Facial Soft Tissue using Finite Element Analysis,https://doi.org/10.1007/978-3-540-68017-8_140,Mohammad,Soft tissue prediction using FEM,Orthognathic and mandibular orthognathic surgery,"The paper describes a computer-based surgery planning and simulation system that combines image processing, geometrical modeling, and finite element analysis (FEA) to predict and simulate postoperative facial soft tissue. The approach uses surface-based triangulation of the finite element method. The facial model is assumed to have isotropic, homogeneous, and linear properties for the FEA, which employs quadrilateral elements and mathematical formulations for strain and stress calculations. The system utilizes commercial tools for geometric modeling, surgical planning, visualization, and rendering","The simulated results were qualitatively validated through registration with actual postoperative photographs. Quantitative evaluation was performed using a color map showing error measurements in the range of pseudo-coloring, which defines the distance of facial areas influenced by the surgery. Positive values (hot colors) indicated vital areas of facial changes, while negative values indicated the contrary. The highest deviation point was found around the inner side of the chin, supporting that mandibular movement most affects this area","The study assumes the facial model has isotropic, homogeneous, and linear properties due to limitations in mathematical formulation and hardware resources, despite biological tissue being anisotropic, non-homogeneous, and non-linear. The current surface-based model prioritizes visually acceptable results and does not incorporate advanced anatomical features like muscular anatomy, fat, and nerves, which would require volumetric models composed of tetrahedral elements. Additionally, the exact replication of real-world surgery, including the use of plates and screws, was not considered in detail",Private (no link),CT scans,N/R,N/R,N/R,N/R
Multiscale Mechano-Biological Finite Element Modelling of Oncoplastic Breast Surgery—Numerical Study towards Surgical Planning and Cosmetic Outcome Prediction,https://doi.org/10.1371/journal.pone.0159766,Mohammad,Multi-scale FEM for solving temporal momentum equations,Breast Conserving Surgery,"This study presents an integrated numerical framework to simulate breast conserving therapy (BCT) outcomes over time. It employs a 3D multiscale finite element procedure for breast tissue deformation and physiological wound healing. The framework combines mathematical models for tissue recovery, angiogenesis, and breast tissue biomechanics, including a five-species physiological wound healing model and a hyperelastic constitutive law for breast tissues. The coupled multiscale FE procedure, implemented in C++, solves non-linear reaction-diffusion and linear momentum equations, using a partitioned approach for different time scales.","The numerical scheme's accuracy was demonstrated with patient-specific examples. Post-operative breast shape predictions, derived from MRI and simulated wound healing, were validated against optical surface scans from four patients. Mean surface distance errors were 2.8 to 4.1 millimeters, indicating clinically useful accuracy for pre-operative BCT outcome prediction.","A key limitation arises from MRI acquisitions, where skin contact with the scanner introduces uncontrolled forces, making gravity not the sole load. Since experimental measurement of these contact forces is not feasible, the FE model preparation ignored contact and friction. This omission could lead to inaccurate estimation of the gravity-free breast geometry from inverse simulation.","[PUBLIC] The analyzed image data, FE model data, and a stable version of the FE code are openly accessible on figShare under the project ""Multiscale Mechano-biological Finite Element Modelling of Oncoplastic Breast Surgery.""

Analyzed image data: https://dx.doi.org/10.6084/m9.figshare.3474584.v1

FE model data: https://dx.doi.org/10.6084/m9.figshare.3464237.v1

FE code: https://dx.doi.org/10.6084/m9.figshare.3464222.v1",6 patients: MRI,N/R,N/R,N/R,Royal Free Hospital in London
"Breast Conserving Surgery Outcome Prediction: A Patient-Specific, Integrated Multi-modal Imaging and Mechano-Biological Modelling Framework",https://doi.org/10.1007/978-3-319-41546-8_35,Mohammad,FEM-based mechano-biological modeling,Breast Conserving Surgery,"The paper presents a processing workflow that integrates MR images and three-dimensional optical surface scans into a personalized mechano-biological model. This model utilizes an interactively generated surgical plan and an open-source finite element solver to simulate breast deformity based on physiological and biomechanical processes occurring post-surgery. The workflow involves generating a patient-specific biomechanical model from MRI scans, reconstructing 3D surface models using systems like 3dMD or Microsoft Kinect, and then performing surgical simulations that account for tissue mechanics and wound healing. A model-to-surface alignment procedure is used to refine the upright simulation by optimizing material parameters and applying surface warping.",The outcome predictions were validated by comparing the simulated outcome with follow-up surface scans of four patients acquired 6 to 12 months post-surgery. A mean absolute surface distance of 3.3 mm between the follow-up scan and the simulation was obtained across all four cases. The results indicate that the mechano-biological simulation predicts the overall breast deformity well and with clinically useful accuracy,"One limitation noted is the relatively large time gap (6-12 months) between baseline and follow-up scans, during which breast shape might change due to effects unrelated to surgery, such as weight loss or gain. Such effects are not currently considered by the surgical outcome prediction, which can increase the measured surface distance. Additionally, inaccuracies in the model can persist due to uncertainties in patient-specific material parameters and deformations of the breast during prone MRI acquisition",Private (no link),4 patients: surface scans,N/R,N/R,N/R,Royal Free Hospital in London
Multiscale modeling and distributed computing to predict cosmesis outcome after a lumpectomy,https://doi.org/10.1016/j.jcp.2012.08.002,Mohammad,FEM ,breast-conserving therapy,"The paper proposes a multiscale computational framework that couples different mechanical and biological models with heterogeneous distributed computing. The method involves modeling tissue mechanics using a Neo-Hookean hyperelastic model implemented in ANSYS™ finite element software, and wound healing at the cellular level using a Cellular Automata (CA) model. The CA model incorporates cell division at the wound edge and within the active layer, as well as cell mobility and redistribution based on diffusion operators and local environmental conditions like Tissue Growth Factor (TGF) concentration and mechanical strain energy. The overall process is iterative, with the mechanical model providing strain energy distribution to the CA model, which in turn updates the geometry based on healing progression. This framework is designed with a modular software approach for easy interchangeability of sub-models","The authors conducted performance evaluations of their distributed computing framework, particularly the parallel implementation of the Cellular Automata (CA) code on a SiCortex system. The CA code, written in C and utilizing MPI 2.0, demonstrated good scaled efficiency despite its arithmetic complexity being higher than linear (order N^3). Communication overhead between processors was remarkably low, less than 0.1% of the total computation time for a week of simulated healing. The mechanical model accounted for approximately 3% of the total computation time, and inter-system communication was about 0.5%. The overall performance indicates that the CA code dominates the elapsed time, and the implementation is deemed adequate, although the explicit algorithm itself does not scale linearly.","The current model has several limitations: the initial work is limited to two spatial dimensions for simplicity, although the concept extends to three dimensions. Patient-specific data access in real clinical conditions is limited, and while MRI provides geometric information, spatially accurate breast tissue composition and mechanical properties are difficult to obtain. The 3D surface reconstruction from model simulation still requires subjective interpretation, suggesting a more realistic goal might be cosmetic and functional indicators. The healing model is a simplified phenomenological description with large uncertainties in biological data, and it does not currently include the impact of radiotherapy on healing. Furthermore, the stiffness of new scar tissue is time and possibly load-dependent, which is not fully incorporated, and the final wound closure shape is currently independent of the healing path unless ΔL depends on time. The model will need careful calibration with patient data.",Private (no link),,,,,
Correlation of prediction and actual outcome of three-dimensional simulation in breast augmentation using a cloud-based program,https://doi.org/10.1007/s00266-017-0830-2,Mohammad,Surgeons assessed similarity,breast augmentation surgery,"This retrospective study compared 6-month post-operative outcomes with 3D simulations generated by Crisalix software for 20 patients who underwent bilateral breast augmentation. Similarities between the post-operative and simulated images were assessed by three attending plastic surgeons and ten plastic surgery residents across various parameters, including overall appearance, breast height, breast width, breast volume, breast projection, and nipple correction.","Images were evaluated by three attending plastic surgeons and ten plastic surgery residents. Each evaluator scored the similarity between the 3D simulation and the actual post-operative outcome from 0 to 100 for overall appearance, breast width, breast height, projection, volume, and nipple correction, with 75 representing a good simulation. Evaluators also assessed whether the post-operative outcome was superior (+1), similar (0), or inferior (-1) to the 3D simulation. Statistical analysis included calculating means and standard deviations, stratifying by evaluator type (resident/attending) and breast type (symmetric/tuberous/ptotic), and using t-tests and one-way ANOVA for correlation assessment","The study's limitations include a small sample size of only 20 patients, with even smaller sub-samples when stratified by breast deformity. All patients received smooth, round implants in the sub-glandular plane, limiting the generalizability to other implant types or insertion planes. The study also speculated on patient satisfaction based on aesthetic appeal rather than direct patient feedback, suggesting that further analysis of patient perspectives would be beneficial.",Private (no link),20 patients: preop images,N/R,N/R,N/R,1 center
